attention_dropout: 0.15 #0.1
batch_size: 128 #64 #256
betas:
- 0.9
- 0.999
checkpoints_path: "./checkpoints/medium_diverse/PDT-oracle"
clip_grad: 0.25
deterministic_torch: false
device: cuda
embedding_dim: 128
embedding_dropout: 0 #0.1
env_name: "antmaze-medium-diverse-v2"
episode_len: 1000
eval_episodes: 10 #15
eval_every: 5000
eval_seed: 43 #42 or -1 to seed every run the same
group: "dt-antmaze-medium-PDT-oracle"
learning_rate: 0.0002 #0.0001 #0.004
max_action: 1.0
name: "PDT-oracle"
num_heads: 2
num_layers: 3
num_workers: 4
project: "CORL"
residual_dropout: 0.15 #0.1
reward_scale: 1.0
seq_len: 10 #10
target_returns: [1.0]
train_seed: 16 #10
update_steps: 100000
warmup_steps: 10000
weight_decay: 0.0001
log_attn_weights: 1
log_attn_every: 250
record_video: 1
run_name: "debug" # run_228
eval_offline_every: 5000
bg_image: "./bg_images/antmaze_medium_bg.png"
eval_path_plot_every: 2500
num_plan_points: 10
plan_bar_visualisation: false
replanning_interval: 10 #80
num_eval_videos: 1
action_noise_scale: 0.7 # 0.7
plan_sampling_method:  4 # 1: fixed-time", 2: fixed-distance", 3: log-time", 4: log-distance
plan_max_trajectory_ratio: 0.5 # 0.5
state_noise_scale: 0.0 # 0.0
plan_combine_observations: False
plan_disabled: False
use_two_phase_training: false # false
is_goal_conditioned: true # true
goal_indices: [0,1]
plan_indices: [0,1]
path_viz_indices: [0,1]
plans_use_actions: false
non_plan_downweighting: 0 #-2
use_timestep_embedding: false
demo_mode: false
plan_use_relative_states: true
goal_representation: 3 # 1: Absolute Goal, 2: Relative goal, 3: State project to Goal and Absolute Goal

#checkpoint_to_load: PDT-oracle-antmaze-medium-diverse-v2-85532219 # run 226
#checkpoint_step_to_load: 99999

#checkpoint_to_load: PDT-oracle-antmaze-medium-diverse-v2-199653d3 # no timestep emb + goal emb + sub
#checkpoint_step_to_load: 99999
#checkpoint_to_load: PDT-oracle-antmaze-medium-diverse-v2-3cc51615
#checkpoint_step_to_load: 60000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-8862433e" # goal_emb + don't subtract state
#checkpoint_step_to_load: 80000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-8862433e" # goal_emb + don't subtract state
#checkpoint_step_to_load: 80000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-c434a818" # multitoken
#checkpoint_step_to_load: 99999
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-95145aa6" # fixed plan head
#checkpoint_step_to_load: 30000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-36129aa0" # No plan
#checkpoint_step_to_load: 70000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-66e6774d" # debug the log distance, pos state
#checkpoint_step_to_load: 99999
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-66e3aa73" # improved return weighting - the 1.0 run v2 (run 61)
#checkpoint_step_to_load: 80000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-b8e52e53" # seq10, batch128 0.8667 w/0.377 dist (best, 0.96)
#checkpoint_step_to_load: 30000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-8fe284d8" # seq10 0.8667 w/0.27 dist
#checkpoint_step_to_load: 10000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-053c7cc1" # goal dist sample 0.8 w/0.22 dist
#checkpoint_step_to_load: 30000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-053c7cc1" # the 0.9 run with 0.39 dist (run 40)
#checkpoint_step_to_load: 100000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-01f5fc18" # the 1.0 run (run 44)
#checkpoint_step_to_load: 25000
#checkpoint_to_load: "PDT-oracle-antmaze-medium-diverse-v2-a166a802"